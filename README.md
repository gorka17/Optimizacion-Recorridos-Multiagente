# Optimizaci贸n de recorridos con Aprendizaje por Refuerzo Multiagente (MARL)

La optimizaci贸n de recorridos es un problema clave en sectores como la log铆stica, el transporte, la planificaci贸n urbana o la distribuci贸n de recursos. Resolverlo de manera eficiente no solo reduce costes y tiempos, sino que tambi茅n mejora la utilizaci贸n de recursos y la calidad del servicio.

Tradicionalmente, este tipo de problemas se han abordado mediante algoritmos de optimizaci贸n cl谩sica (heur铆sticas, algoritmos gen茅ticos, etc.). Sin embargo, el **Aprendizaje por Refuerzo Multiagente (MARL)** ofrece un enfoque prometedor: permite que varios agentes aprendan en un entorno compartido, desarrollando estrategias colaborativas o competitivas para alcanzar objetivos individuales y globales.

Este proyecto explora el potencial de los sistemas MARL para resolver problemas de optimizaci贸n de recorridos. Se ha utilizado como base el repositorio [MultiAgentSB3](https://github.com/inakivazquez/MultiAgentSB3), que proporciona entornos multiagente compatibles con **Stable-Baselines3 (SB3)** y facilita la implementaci贸n y entrenamiento de agentes en escenarios multiagente de manera similar a los de agente 煤nico.

---

## Puntos clave del proyecto
- **Dise帽o de entornos multiagente:** modelado de problemas de optimizaci贸n como escenarios MARL.  
- **Entrenamiento con Stable-Baselines3:** uso de algoritmos de Deep RL adaptados a m煤ltiples agentes.  
- **Aprendizaje colaborativo y competitivo:** an谩lisis de c贸mo los agentes coordinan sus acciones para mejorar el rendimiento global.   

---

## Lo que he aprendido
Este proyecto me ha permitido:  
- Diferenciar claramente entre entornos de **agente 煤nico** y **multiagente**.  
- Aprender a **modelar problemas reales** como entornos de RL, definiendo estados, acciones y recompensas.  
- Utilizar frameworks modernos como **Stable-Baselines3** y extensiones para MARL.  
- Comprender el papel de la **cooperaci贸n y coordinaci贸n** en la optimizaci贸n de sistemas multiagente.  
- Evaluar de manera cr铆tica las **ventajas y limitaciones del MARL** frente a enfoques tradicionales de optimizaci贸n.  

---

##  Recursos
- Repositorio base: [MultiAgentSB3](https://github.com/inakivazquez/MultiAgentSB3)  
- Frameworks utilizados: Stable-Baselines3 (SB3), Gym  

---

##  Ejemplo de ruta optimizada
![Ruta optimizada](ejemplo_ruta.png)

